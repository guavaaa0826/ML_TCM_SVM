{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Team 13 TCM SVM ver.\n",
    "\n",
    "This is the model built by SVM.\n",
    "Powered by ChatGPT. LOL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Package import\n",
    "\n",
    "Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Data preparation\n",
    "\n",
    "1. Read data from the .csv file as a Pandas DataFrame.\n",
    "2. Change the columns with texts into numeric values using LabelEncoder.\n",
    "3. Split the data into the status/diagnoses/symptoms and the prescriptions.\n",
    "4. Delete the CHMs that are not often used enough.\n",
    "5. Split the data into training data and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset(REMINDER: The data is edited):\n",
    "# Indexing(not used): 0\n",
    "# Body status: 1~3\n",
    "# Diagnosis: 4~7\n",
    "# Prescription-text(not used): 8~10\n",
    "# Symptom: 11~125\n",
    "# Prescription: 126~226\n",
    "\n",
    "# Total patient data: 797\n",
    "\n",
    "# 1. Read data from the .csv file as a Pandas DataFrame.\n",
    "def ReadData(FILENAME):\n",
    "    data = pd.read_csv(FILENAME)\n",
    "    # Debug\n",
    "    print(\"ReadData:\")\n",
    "    print(f'Shape of data = ({data.shape[0]}, {data.shape[1]}).')\n",
    "    return data\n",
    "\n",
    "# 2. Change the columns with texts into numeric values using LabelEncoder.\n",
    "def TextConvert(data):\n",
    "   # Body status: 1~3, Diagnosis: 4~7\n",
    "    label_encoder = LabelEncoder()\n",
    "    categorical_columns = list(range(1, 8))\n",
    "    for i in categorical_columns:\n",
    "        data.iloc[:, i] = label_encoder.fit_transform(data.iloc[:, i])\n",
    "    return data\n",
    "\n",
    "# 3. Split the data into the status/diagnoses/symptoms and the prescriptions.\n",
    "def SplitXY(data):\n",
    "    # Body status: 1~3, Diagnosis: 4~7, Symptom: 11~124\n",
    "    # Prescription: 125~226\n",
    "    split_X = list(range(1, 8)) + list(range(11, 126))\n",
    "    split_Y = list(range(125, 227))\n",
    "    X = data.iloc[1:, split_X]\n",
    "    y = data.iloc[1:, split_Y]\n",
    "    # Debug\n",
    "    print(\"SplitXY:\")\n",
    "    print(f'Shape of X = ({X.shape[0]}, {X.shape[1]}). First 10 data of X:')\n",
    "    print(X.iloc[:10, :10])\n",
    "    print(f'Shape of y = ({y.shape[0]}, {y.shape[1]}). First 10 data of y:')\n",
    "    print(y.iloc[:10, :10])\n",
    "    return X, y\n",
    "\n",
    "# 4. Delete the CHMs that are not often used enough.\n",
    "def DeleteMedicine(y):\n",
    "    threshold = 10\n",
    "    for col in y.columns:\n",
    "        if y[col].sum() < threshold:\n",
    "            y = y.drop(col, axis=1)\n",
    "    \n",
    "\n",
    "# 5. Split the data into training data and validation data.\n",
    "def SplitTrainValid(X, y):\n",
    "    state = 114514\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=state, stratify=y)\n",
    "    # Debug\n",
    "    print(\"SplitTrainValid:\")\n",
    "    print(f'shape of X_train is ({X_train.shape[0]}, {X_train.shape[1]}).')\n",
    "    print(f'shape of X_test is ({X_test.shape[0]}, {X_test.shape[1]}).')\n",
    "    print(f'shape of y_train is ({y_train.shape[0]}, {y_train.shape[1]}).')\n",
    "    print(f'shape of y_test is ({y_test.shape[0]}, {y_test.shape[1]}).')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Build the SVM model\n",
    "\n",
    "For the information about sklearn SVC, go to: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "1. Build the SVM classfier.\n",
    "2. Use the model to predict the data.\n",
    "3. Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build the SVM classfier.\n",
    "def SVMModel(X_train, y_train):\n",
    "    svm_model = MultiOutputClassifier(SVC(kernel='rbf', C=1.0)) # TODO: Determine the kernel function.\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    return svm_model\n",
    "\n",
    "# 2. Use the model to predict the data.\n",
    "def Predict(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "# 3. Evaluate the model's performance.\n",
    "def Evaluate(y_test, y_pred) :\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print('Accuracy: ' + accuracy)\n",
    "    print(f'Confusion Matrix:\\n' + conf_matrix)\n",
    "    print(f'Classification Report:\\n' + class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Main code and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReadData:\n",
      "Shape of data = (797, 227).\n",
      "SplitXY:\n",
      "Shape of X = (796, 122). First 10 data of X:\n",
      "   性別 年齡及體型 月經 脈診 舌診 眼診 耳診  乳癌  肺癌  胰臟癌\n",
      "1   0     0  1  0  3  1  1   0   0    0\n",
      "2   0     0  1  0  3  1  1   0   0    0\n",
      "3   0     2  1  1  3  1  1   0   0    0\n",
      "4   0     2  1  0  0  1  1   0   0    0\n",
      "5   0     2  1  1  3  1  1   0   0    0\n",
      "6   0     2  1  0  3  1  1   0   0    0\n",
      "7   0     0  1  0  3  1  1   0   0    0\n",
      "8   0     0  1  0  3  1  1   0   0    0\n",
      "9   0     0  0  1  2  1  1   0   0    0\n",
      "10  0     0  1  1  3  1  1   0   0    0\n",
      "Shape of y = (796, 102). First 10 data of y:\n",
      "    麻黃  桂枝  荊芥  防風  細辛  白芷  生薑  辛夷  葛根  升麻\n",
      "1    0   1   0   0   1   1   0   0   0   0\n",
      "2    0   1   0   0   0   0   1   0   0   0\n",
      "3    0   0   0   0   0   0   0   0   0   0\n",
      "4    0   1   0   0   0   0   1   1   0   0\n",
      "5    0   1   0   0   0   0   0   0   0   0\n",
      "6    0   0   0   0   0   0   0   0   0   0\n",
      "7    0   1   0   0   0   0   0   0   0   0\n",
      "8    0   1   0   0   0   0   0   0   0   0\n",
      "9    0   1   0   0   1   0   0   0   0   0\n",
      "10   0   1   0   0   1   0   0   0   0   0\n",
      "Column 麻黃 has sum = 132\n",
      "Column 桂枝 has sum = 337\n",
      "Column 荊芥 has sum = 20\n",
      "Column 防風 has sum = 42\n",
      "Column 細辛 has sum = 249\n",
      "Column 白芷 has sum = 9\n",
      "Column 生薑 has sum = 215\n",
      "Column 辛夷 has sum = 37\n",
      "Column 葛根 has sum = 17\n",
      "Column 升麻 has sum = 14\n",
      "Column 柴胡 has sum = 261\n",
      "Column 蟬蛻 has sum = 16\n",
      "Column 石膏 has sum = 106\n",
      "Column 知母 has sum = 127\n",
      "Column 梔子 has sum = 74\n",
      "Column 天花粉 has sum = 17\n",
      "Column 夏枯草 has sum = 13\n",
      "Column 決明子 has sum = 11\n",
      "Column 生地 has sum = 91\n",
      "Column 牡丹皮 has sum = 8\n",
      "Column 連翹 has sum = 29\n",
      "Column 射干 has sum = 23\n",
      "Column 黃連 has sum = 168\n",
      "Column 黃芩 has sum = 320\n",
      "Column 黃柏 has sum = 54\n",
      "Column 龍膽草 has sum = 109\n",
      "Column 大黃 has sum = 133\n",
      "Column 芒硝 has sum = 48\n",
      "Column 防己 has sum = 72\n",
      "Column 秦艽 has sum = 7\n",
      "Column 絡石藤 has sum = 13\n",
      "Column 蒼朮 has sum = 60\n",
      "Column 草果 has sum = 7\n",
      "Column 茯苓 has sum = 269\n",
      "Column 豬苓 has sum = 81\n",
      "Column 薏苡仁 has sum = 9\n",
      "Column 海金砂 has sum = 7\n",
      "Column 澤瀉 has sum = 298\n",
      "Column 車前子 has sum = 7\n",
      "Column 滑石 has sum = 27\n",
      "Column 木通 has sum = 68\n",
      "Column 通草 has sum = 7\n",
      "Column 赤小豆 has sum = 13\n",
      "Column 燈心草 has sum = 10\n",
      "Column 乾薑 has sum = 183\n",
      "Column 附子 has sum = 346\n",
      "Column 吳茱萸 has sum = 84\n",
      "Column 枳實 has sum = 116\n",
      "Column 烏藥 has sum = 112\n",
      "Column 厚朴 has sum = 117\n",
      "Column 大腹皮 has sum = 8\n",
      "Column 青皮 has sum = 18\n",
      "Column 薤白 has sum = 15\n",
      "Column 麥芽 has sum = 96\n",
      "Column 側柏葉 has sum = 40\n",
      "Column 槐花 has sum = 15\n",
      "Column 三七 has sum = 12\n",
      "Column 茜草 has sum = 124\n",
      "Column 川芎 has sum = 218\n",
      "Column 乳香 has sum = 11\n",
      "Column 延胡索 has sum = 8\n",
      "Column 鬱金 has sum = 118\n",
      "Column 紅花 has sum = 7\n",
      "Column 桃仁 has sum = 45\n",
      "Column 牛膝 has sum = 34\n",
      "Column 半夏 has sum = 201\n",
      "Column 白附子 has sum = 24\n",
      "Column 桔梗 has sum = 38\n",
      "Column 旋覆花 has sum = 65\n",
      "Column 瓜蔞 has sum = 12\n",
      "Column 海藻 has sum = 24\n",
      "Column 杏仁 has sum = 80\n",
      "Column 紫菀 has sum = 13\n",
      "Column 龍骨 has sum = 50\n",
      "Column 牡蠣 has sum = 134\n",
      "Column 酸棗仁 has sum = 35\n",
      "Column 遠志 has sum = 40\n",
      "Column 小麥 has sum = 15\n",
      "Column 代赭石 has sum = 79\n",
      "Column 黃耆 has sum = 55\n",
      "Column 白朮 has sum = 222\n",
      "Column 大棗 has sum = 190\n",
      "Column 甘草 has sum = 450\n",
      "Column 巴戟天 has sum = 39\n",
      "Column 補骨脂 has sum = 200\n",
      "Column 益智仁 has sum = 8\n",
      "Column 陽起石 has sum = 48\n",
      "Column 續斷 has sum = 15\n",
      "Column 杜仲 has sum = 18\n",
      "Column 何首烏 has sum = 23\n",
      "Column 當歸 has sum = 263\n",
      "Column 白芍 has sum = 422\n",
      "Column 阿膠 has sum = 100\n",
      "Column 西洋參 has sum = 7\n",
      "Column 龜板 has sum = 38\n",
      "Column 鱉甲 has sum = 48\n",
      "Column 山茱萸 has sum = 14\n",
      "Column 覆盆子 has sum = 11\n",
      "Column 五味子 has sum = 32\n",
      "Column 烏梅 has sum = 12\n",
      "Column 五倍子 has sum = 13\n",
      "Column 炙甘草 has sum = 474\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\poyiw\\Test\\tcm_svm\\ML_TCM_SVM\\tcm_svm.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X, y \u001b[39m=\u001b[39m SplitXY(data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m OneDataCounter(y)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m SplitTrainValid(X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mData preparation completed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Step 3 functions\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\poyiw\\Test\\tcm_svm\\ML_TCM_SVM\\tcm_svm.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSplitTrainValid\u001b[39m(X, y):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39m114514\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.4\u001b[39;49m, random_state\u001b[39m=\u001b[39;49mstate, stratify\u001b[39m=\u001b[39;49my)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m# Debug\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/poyiw/Test/tcm_svm/ML_TCM_SVM/tcm_svm.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSplitTrainValid:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\poyiw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\poyiw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2670\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2666\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2668\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2670\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X\u001b[39m=\u001b[39;49marrays[\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mstratify))\n\u001b[0;32m   2672\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2673\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2674\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2675\u001b[0m     )\n\u001b[0;32m   2676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\poyiw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1746\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1743\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1745\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1746\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1747\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\poyiw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2147\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2145\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2146\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 2147\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2148\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2150\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2151\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2152\u001b[0m     )\n\u001b[0;32m   2154\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[0;32m   2155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2157\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2158\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# Step 2 functions\n",
    "FILENAME = './process_data.csv'\n",
    "data = ReadData(FILENAME)\n",
    "data = TextConvert(data)\n",
    "X, y = SplitXY(data)\n",
    "DeleteMedicine(y)\n",
    "X_train, X_test, y_train, y_test = SplitTrainValid(X, y)\n",
    "print(\"Data preparation completed.\")\n",
    "\n",
    "# Step 3 functions\n",
    "model = SVMModel(X_train, y_train)\n",
    "y_pred = Predict(model, X_test)\n",
    "Evaluate(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
