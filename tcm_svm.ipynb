{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Team 13 TCM SVM ver.\n",
    "\n",
    "This is the model built by SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Package import\n",
    "\n",
    "Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Data preparation\n",
    "\n",
    "1. Read data from the .csv file as a Pandas DataFrame.\n",
    "2. Change the columns with texts into numeric values using LabelEncoder.\n",
    "3. Split the data into the status/diagnoses/symptoms and the prescriptions.\n",
    "4. Delete the CHMs that are not often used enough.\n",
    "5. Split the data into training data and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset(REMINDER: The dataset is edited):\n",
    "# Index(not used): 0\n",
    "# Body status: 1~3\n",
    "# Diagnosis: 4~7\n",
    "# Prescription_text(not used): 8~10\n",
    "# Symptom: 11~125\n",
    "# Prescription: 126~226\n",
    "\n",
    "# Total patient data: 797\n",
    "\n",
    "# 1. Read data from the .csv file as a Pandas DataFrame.\n",
    "def ReadData(FILENAME):\n",
    "    data = pd.read_csv(FILENAME)\n",
    "    return data\n",
    "\n",
    "# 2. Change the columns with texts into numeric values using LabelEncoder.\n",
    "def TextConvert(data):\n",
    "    # Converting: 1~7 (Body status + Diagnosis)\n",
    "    label_encoder = LabelEncoder()\n",
    "    categorical_columns = list(range(1, 8))\n",
    "    for i in categorical_columns:\n",
    "        data.iloc[:, i] = label_encoder.fit_transform(data.iloc[:, i])\n",
    "    return data\n",
    "\n",
    "# 3. Split the data into the status/diagnoses/symptoms and the prescriptions.\n",
    "def SplitXY(data):\n",
    "    # X: 1~7 + 11~124 (Body status + Diagnosis + Symptom)\n",
    "    # Y: 125~226 (Prescription)\n",
    "    split_X = list(range(1, 8)) + list(range(11, 126))\n",
    "    split_Y = list(range(125, 227))\n",
    "    X = data.iloc[1:, split_X]\n",
    "    y = data.iloc[1:, split_Y]\n",
    "    return X, y\n",
    "\n",
    "# 4. Delete the CHMs that are not often used enough.\n",
    "def DeleteMedicine(y, threshold):\n",
    "    for col in y.columns:\n",
    "        if y[col].sum() < threshold:\n",
    "            y = y.drop(col, axis=1)\n",
    "    print(f\"There are {y.shape[1]} medicines.\")\n",
    "    return y\n",
    "\n",
    "# 5. Split the data into training data and validation data.\n",
    "def SplitTrainValid(X, y):\n",
    "    random_state = 114514\n",
    "    random.seed(random_state)\n",
    "    train_rate = 0.8\n",
    "    border = int(X.shape[0] * train_rate)\n",
    "    \n",
    "    X_temp = X.sample(n=X.shape[0], random_state=random_state)\n",
    "    y_temp = y.sample(n=y.shape[0], random_state=random_state)\n",
    "    X_train = X_temp[:border - 1]\n",
    "    X_test = X_temp[border:]\n",
    "    y_train = y_temp[:border - 1]\n",
    "    y_test = y_temp[border:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Build the SVM model\n",
    "\n",
    "For the information about sklearn SVC, go to: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "1. Build the SVM models.\n",
    "    - Type 1: Multiple models: Build models according to every single columns.\n",
    "    - Type 2: MultiOutputClassifier model: Build the model according to all the columns.\n",
    "    - Type 3: Weighted model: Build the weighted model to handle the imbalanced data.\n",
    "2. Use the model to predict the data.\n",
    "3. Evaluate the model's performance, including the accuracy and the f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build the SVM models.\n",
    "# Type 1: Multiple Models\n",
    "def SVMModel_1(X_train, y_train, C=5):\n",
    "    svm_model = SVC(kernel='rbf', C=C)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    return svm_model\n",
    "\n",
    "# Type 2: MultiOutputClassifier model\n",
    "def SVMModel_2(X_train, y_train, C=5):\n",
    "    svm_model = MultiOutputClassifier(SVC(kernel='rbf', C=C))\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    return svm_model\n",
    "\n",
    "# Type 3: weighted model\n",
    "def SVMModel_3(X_train, y_train, C=5, bias_const=1):\n",
    "    # Generate the dictionary of weight.\n",
    "    class_weight_dic = {}\n",
    "    unique_values, counts = np.unique(y_train, return_counts=True)\n",
    "    value_frequency_dict = dict(zip(unique_values, counts))\n",
    "    total = value_frequency_dict[0] + value_frequency_dict[1]\n",
    "    class_weight_dic = {0: value_frequency_dict[1] / total, 1: bias_const * value_frequency_dict[0] / total}\n",
    "    \n",
    "    svm_model = SVC(kernel='rbf', C=C, class_weight=class_weight_dic)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    return svm_model\n",
    "\n",
    "# 2. Use the model to predict the data.\n",
    "def Predict(model, X_test):\n",
    "    y_pred = pd.DataFrame(model.predict(X_test))\n",
    "    return y_pred\n",
    "\n",
    "# 3. Evaluate the models' performance, including the accuracy and the f1-score.\n",
    "def Evaluate(y_test, y_pred, model_build_principle, acc=False, acc_detail=False, f1=False, f1_detail=False):\n",
    "    total_count = 0\n",
    "    total_accuracy = 0 # Calculate the partial and overall accuracy.\n",
    "    data = [0, 0, 0, 0] # [TP, FP, TN, FN]. Calculate the TP, FP, TN, FN, and f1-score.\n",
    "    for i in range(y_test.shape[0]):\n",
    "        accuracy_temp = accuracy_score(y_test.iloc[i], y_pred.iloc[i])\n",
    "        data_temp = [0, 0, 0, 0]\n",
    "        total_count += 1\n",
    "        total_accuracy += accuracy_temp\n",
    "        if acc_detail == True:\n",
    "            print(f'The accuracy for column {i} is {accuracy_temp}.')\n",
    "        for j in range(y_test.shape[1]):\n",
    "            if y_test.iloc[i, j] == 1 and y_pred.iloc[i, j] == 1:\n",
    "                data_temp[0] += 1\n",
    "            elif y_test.iloc[i, j] == 0 and y_pred.iloc[i, j] == 1:\n",
    "                data_temp[1] += 1\n",
    "            elif y_test.iloc[i, j] == 0 and y_pred.iloc[i, j] == 0:\n",
    "                data_temp[2] += 1\n",
    "            elif y_test.iloc[i, j] == 1 and y_pred.iloc[i, j] == 0:\n",
    "                data_temp[3] += 1\n",
    "        if f1_detail == True:\n",
    "            print(f'TP, FP, TN, and FN for column {i} are [{data_temp[0]}, {data_temp[1]}, {data_temp[2]}, {data_temp[3]}].')\n",
    "        for j in range(4):\n",
    "            data[j] += data_temp[j]\n",
    "    accuracy = total_accuracy / total_count\n",
    "    if acc == True:\n",
    "        print(f'Type {model_build_principle}: The overall accuracy = {accuracy}.')\n",
    "    if f1 == True:\n",
    "        print(f'Type {model_build_principle}:')\n",
    "        print(f'The overall TP, FP, TN, and FN are [{data[0]}, {data[1]}, {data[2]}, {data[3]}].')\n",
    "        precision = data[0] / (data[0] + data[1])\n",
    "        recall = data[0] / (data[0] + data[3])\n",
    "        f1_score = 2 / (1 / precision + 1 / recall)\n",
    "        print(f'The overall f1-score is {f1_score}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Main code and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 medicines.\n",
      "Data preparation completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 2 functions\n",
    "FILENAME = './process_data.csv'\n",
    "data = ReadData(FILENAME)\n",
    "data = TextConvert(data)\n",
    "X, y = SplitXY(data)\n",
    "y = DeleteMedicine(y, threshold=250)\n",
    "X_train, X_test, y_train, y_test = SplitTrainValid(X, y)\n",
    "print(\"Data preparation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 3: The overall accuracy = 0.6781250000000002.\n",
      "Type 3:\n",
      "The overall TP, FP, TN, and FN are [434, 227, 651, 288].\n",
      "The overall f1-score is 0.6276211135213304.\n"
     ]
    }
   ],
   "source": [
    "# Single-time model building\n",
    "model_build_principle = 3\n",
    "# Step 3 functions\n",
    "if model_build_principle == 1:\n",
    "    models = []\n",
    "    for col in y_train.columns:\n",
    "        models.append(SVMModel_1(X_train, y_train[col], C=10))\n",
    "    y_pred = pd.DataFrame()\n",
    "    for i in range(len(models)):\n",
    "        y_temp = Predict(models[i], X_test)\n",
    "        y_pred = pd.concat([y_pred, y_temp], axis=1)\n",
    "elif model_build_principle == 2:\n",
    "    model = SVMModel_2(X_train, y_train, C=10)\n",
    "    y_pred = Predict(model, X_test)\n",
    "elif model_build_principle == 3:\n",
    "    models = []\n",
    "    for col in y_train.columns:\n",
    "        models.append(SVMModel_3(X_train, y_train[col], C=19, bias_const=1.1))\n",
    "    y_pred = pd.DataFrame()\n",
    "    for i in range(len(models)):\n",
    "        y_temp = Predict(models[i], X_test)\n",
    "        y_pred = pd.concat([y_pred, y_temp], axis=1)\n",
    "    \n",
    "Evaluate(y_test, y_pred, model_build_principle, acc=True, f1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative model building - parameter adjustment\n",
    "for c in range(19, 31):\n",
    "    for model_build_principle in range(3, 4):\n",
    "        if model_build_principle == 3:\n",
    "            for bias_const in range(7, 13):\n",
    "                models = []\n",
    "                for col in y_train.columns:\n",
    "                    models.append(SVMModel_3(X_train, y_train[col], C=c, bias_const=bias_const / 10))\n",
    "                y_pred = pd.DataFrame()\n",
    "                for i in range(len(models)):\n",
    "                    y_temp = Predict(models[i], X_test)\n",
    "                    y_pred = pd.concat([y_pred, y_temp], axis=1)\n",
    "                print(f'C = {c}, bias_const = {bias_const}.')\n",
    "                Evaluate(y_test, y_pred, model_build_principle, acc=True, f1=True)\n",
    "        elif model_build_principle == 2:\n",
    "            model = SVMModel_2(X_train, y_train, C=c)\n",
    "            y_pred = Predict(model, X_test)\n",
    "            print(f'C = {c}.')\n",
    "            Evaluate(y_test, y_pred, model_build_principle, acc=True, f1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeleteMedicine: threshold/data number\n",
    "# threshold=7, data number=102\n",
    "# threshold=10, data number=89\n",
    "# threshold=250, data number=10\n",
    "\n",
    "# SVMModel_2: threshold/C/accuracy/f1_score\n",
    "# threshold=10, C=4, accuracy=0.891, f1_score=0.453\n",
    "# threshold=10, C=5, accuracy=0.891, f1_score=0.465\n",
    "# threshold=10, C=6, accuracy=0.890, f1_score=0.472\n",
    "# threshold=10, C=7, accuracy=0.889, f1_score=0.473\n",
    "# threshold=10, C=8, accuracy=0.888, f1_score=0.475\n",
    "# threshold=10, C=9, accuracy=0.888, f1_score=0.479\n",
    "# threshold=10, C=10, accuracy=0.888, f1_score=0.482\n",
    "\n",
    "# SVMModel_3: threshold/C/bias_const/accuracy/f1_score\n",
    "# threshold=10, C=14, bias_const=0.6, accuracy=0.877, f1_score=0.473\n",
    "# threshold=10, C=14, bias_const=0.9, accuracy=0.870, f1_score=0.484\n",
    "# threshold=10, C=15, bias_const=0.7, accuracy=0.875, f1_score=0.480\n",
    "# threshold=10, C=15, bias_const=1.2, accuracy=0.867, f1_score=0.486\n",
    "# threshold=10, C=16, bias_const=0.7, accuracy=0.876, f1_score=0.481\n",
    "# threshold=10, C=16, bias_const=1.2, accuracy=0.869, f1_score=0.489\n",
    "# threshold=10, C=17, bias_const=0.7, accuracy=0.877, f1_score=0.480\n",
    "# threshold=10, C=17, bias_const=1.2, accuracy=0.869, f1_score=0.486\n",
    "# threshold=10, C=18, bias_const=0.7, accuracy=0.877, f1_score=0.481\n",
    "# threshold=10, C=18, bias_const=0.8, accuracy=0.875, f1_score=0.485\n",
    "# threshold=10, C=19, bias_const=0.8, accuracy=0.875, f1_score=0.483\n",
    "# threshold=10, C=19, bias_const=1.1, accuracy=0.872, f1_score=0.487\n",
    "# threshold=10, C=20, bias_const=0.8, accuracy=0.875, f1_score=0.481\n",
    "# threshold=10, C=20, bias_const=1.1, accuracy=0.872, f1_score=0.485\n",
    "\n",
    "# TODO:\n",
    "# Completed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
